---
layout: post
title:  "Human Face Image Render and Reconstruction"
info: "A framework to render human face images through calculating the direction and nature of a single light source."
tech : "Python & MATLAB"
type: Project
---
<h2><center>A framework to render human face images</center></h2>

Click here to see the [code](https://github.com/XUANTONG1999/Face-Image-Rendering-and-Reconstruction).

## Ⅰ. Introduction

Given the surface reflectivity of an object, normal factor directions and other data, we are able to get the render results of various illumination conditions and observation views, based on some **Surface Reflection Model**(Lambertian).

With the development of 3D Rendering Technologies, more accurate models of reflection have been proposed, to make the render results as close to the real world images as possible. We consider the reverse process of the above process, that is, given the rendering results of different illumination and views, the surface reflectance and normal vector information of the object can be inferred through the surface reflection model, which can further obtain depth information for 3D reconstruction. The results of 3D reconstruction can be verified by the forward rendering effects.

However, in the general natural environment, illumination information is extremely complex and difficult to obtain, so it is not easy to realize the above prediction.

## Ⅱ. Integrated solution

Under the condition of a single constant intensity light source in a fixed direction, the luminance of each point on the human face is closely related to the direction of the normal vector of the point.

Firstly, to simplify the problem, we consider a complete diffuse model. For each point of the forward face image $$(x,y)$$:
<br/>
$$
\textbf{b}(x,y)=k_d(x,y)\frac{(z_x(x,y),z_y(x,y),-1)}{\sqrt{z_x^2(x,y)+z_y^2(x,y)+1}}
$$
<br/>

$$z(x,y),k_d(x,y)$$​ are the depth and albedo of corresponding point $$(x,y)$$.

Let the direction of light be $$\bf s$$​, when s is not at a large angle to the z axis, the face image $$m$$ obtained almost contains no shadows and highlights, so its result should be close to the rendering result obtained by diffuse reflection, that is:
<br/>
$$
m(x,y)=\max(\textbf{b}^T(x,y){\bf {s}},0)
$$
<br/>
Therefore, when the number of images in the training set exceeds $$3$$, the optimization algorithm can be used to optimize $$\textbf {b}$$, supplemented by the continuity constraint of $$z$$​​​, and the depth of each point in the face image can be estimated to achieve 3D reconstruction of the face.

On the basis of the 3D reconstruction results, we can further render the face images under the new light angles.



